{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выравнивание изображений номеров автомобилей\n",
    "### Команда: **Keter**\n",
    "#### Саляев Артём, Янковский Егор, Янковский Фёдор\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритм задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм решения задачи в общем виде представлен на рисунке ниже. Реализуя процесс деформации изображений, было принято решение процедуру разделить на три этапа: \n",
    "1. с помощью нейронной сети решим задачу сегментации изображения и выделим номер автомобиля относительно всего изображения;\n",
    "2. с помощью традиционных методов преобразования изображений очертим контур автомобильного номера и получим 3 или 4 точки, соответствующие углам автомобильного номера;\n",
    "3. используя аффинные преобразования, преобразуем наше изображение к исходному шаблону для задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://sun9-2.userapi.com/impg/SfgCnkIYJeC_4clAh69dvC6ZwmBT9dLmMkh25A/DvScgey4ZCg.jpg?size=1916x1079&quality=96&sign=2ef5e9fadc1d8635c4963fb99affd07d&type=album)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 0. Подготовительный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключаем необходмые пакеты\n",
    "\n",
    "from Modules.template import *\n",
    "from Modules.model import *\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объявляем рабочие директории\n",
    "\n",
    "DATASET_PATH = 'images/'\n",
    "MODEL_PATH = './resnet18_letters.pth'\n",
    "LOCAL_PATH = 'temp_crops/'\n",
    "images_pth = ['./images/' + p.name for p in Path('images').iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции для записи и удаления изображений\n",
    "\n",
    "def writeTo(images, path):\n",
    "    for i, image in enumerate(images):\n",
    "        cv.imwrite(f'{path}{i}.jpg', image)\n",
    "\n",
    "def removeFrom(path):\n",
    "    for f in Path(path).iterdir():\n",
    "        os.remove(f.absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Рисует на изображение template\n",
    "def draw_regions(img, region_length):\n",
    "    if region_length == 2:\n",
    "        pattern = two_digit_region_template\n",
    "    elif region_length == 3:\n",
    "        pattern = three_digit_region_template\n",
    "    else:\n",
    "        raise ValueError(\"Неподдерживаемое разбиение на регионы. Поддерживаются только 2 и 3.\")\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        H,W = img.shape\n",
    "    else:\n",
    "        H, W, _ = img.shape\n",
    "\n",
    "    if H != 112 or W != 512:\n",
    "        raise ValueError(\"Форма изображения должна быть 512x112\")\n",
    "\n",
    "    for pos in pattern:\n",
    "        sx, sy, ex, ey = *pos[\"p1\"], *pos[\"p2\"]\n",
    "        sx, sy, ex, ey = int(sx * W), int(sy * H), int(ex * W), int(ey * H)\n",
    "        cv.rectangle(img, (sx, sy), (ex, ey), (0, 255, 0), 2)\n",
    "\n",
    "    return img\n",
    "\n",
    "#Визуализирует изображения из датасета\n",
    "def draw(folder_path, show_template=False, template=2):\n",
    "\n",
    "    file_list = os.listdir(folder_path)\n",
    "    image_files = [f for f in file_list if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "\n",
    "    # Устанавливаем количество изображений на строку\n",
    "    images_per_row = 5\n",
    "\n",
    "    num_rows = len(image_files) // images_per_row + int(len(image_files) % images_per_row != 0)\n",
    "    fig, axes = plt.subplots(num_rows, images_per_row, figsize=(15, 3 * num_rows))\n",
    "\n",
    "    for i in range(num_rows * images_per_row):\n",
    "        if i < len(image_files):\n",
    "            ax = axes.flat[i]\n",
    "            img_path = os.path.join(folder_path, image_files[i])\n",
    "            img = cv.imread(img_path)\n",
    "            img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "            if show_template:\n",
    "              img = img_deformation(img)\n",
    "              img = cv.resize(img, (512,112))\n",
    "              img_with_rectangles = draw_regions(img, template)\n",
    "\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            ax.set_title(os.path.basename(img_path))\n",
    "        else:\n",
    "            axes.flat[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовый вывод без применения решения.\n",
    "# Отрисовывем разбитое по шаблону изображение\n",
    "# и выводим предсказание модели\n",
    "\n",
    "test = cv.imread(images_pth[0])\n",
    "test = cv.resize(test,(512, 112), fx=1, fy=1, interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "crops = apply_template(test, 2)\n",
    "writeTo(crops, 'temp_crops/')\n",
    "\n",
    "model = LettersPrediction()\n",
    "print(model.predict_series(crops))\n",
    "\n",
    "draw('temp_crops')\n",
    "removeFrom('temp_crops/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1. Использование нейросети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "*Блоки кода*\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_segmentation(img):\n",
    "    img = cv.resize(img, (512, 112), fx=1, fy=1, interpolation=cv.INTER_CUBIC)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2. Поиск угловых точек автомобильного номера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unnecessary_vertexes(vertexes, w, h):\n",
    "    left_up =    [w, h]\n",
    "    right_up =   [0, h]\n",
    "    right_down = [0, 0]\n",
    "    for vertex in vertexes:\n",
    "        if left_up[0] ** 2 + left_up[1] ** 2 > vertex[0] ** 2 + vertex[1] ** 2:\n",
    "            left_up = vertex\n",
    "        if (w - right_up[0]) ** 2 + right_up[1] ** 2 > (w - vertex[0]) ** 2 + vertex[1] ** 2:\n",
    "            right_up = vertex\n",
    "        if (w - right_down[0]) ** 2 + (h - right_down[1]) ** 2 > (w - vertex[0]) ** 2 + (h - vertex[1]) ** 2:\n",
    "            right_down = vertex\n",
    "    return [left_up, right_up, right_down]\n",
    "\n",
    "def adaptive(img):\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    blur = cv.GaussianBlur(gray, (27,27), 0)\n",
    "    #kernel = np.ones((5,5), np.uint8)\n",
    "    thresh = cv.adaptiveThreshold(blur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 15, 2)\n",
    "    return thresh\n",
    "\n",
    "def global_thresh(img):\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    blur = cv.GaussianBlur(gray, (17,17), 0)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    ret, thresh = cv.threshold(blur, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    return thresh\n",
    "\n",
    "def stof_blur(img):\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    # blur\n",
    "    blur = cv.GaussianBlur(gray, (0,0), sigmaX=33, sigmaY=33)\n",
    "    # divide\n",
    "    divide = cv.divide(gray, blur, scale=255)\n",
    "    # otsu threshold\n",
    "    thresh = cv.threshold(divide, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)[1]\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (1,1))\n",
    "    morph = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel)\n",
    "    return morph\n",
    "\n",
    "\n",
    "def find_vertex(img):\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    #img = cv.resize(img, (img.shape[0] * 3, img.shape[1] // 3), fx=1, fy=1, interpolation=cv.INTER_CUBIC)\n",
    "    \n",
    "    thresh = adaptive(img)\n",
    "    #thresh = global_thresh(img)\n",
    "    #thresh = stof_blur(img)\n",
    "    \n",
    "    conts, hier = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = sorted(conts, key=cv.contourArea, reverse=True)[:5]\n",
    "    \n",
    "    points = []\n",
    "    for cont in cnts:\n",
    "        perimeter = cv.arcLength(cont, True)\n",
    "        approx = cv.approxPolyDP(cont, 0.02 * perimeter, True)\n",
    "        hull = cv.convexHull(approx, returnPoints=True)\n",
    "        if len(hull) in range(1, 11) and cv.contourArea(hull) / 512 / 112 > 0.3:\n",
    "            for point in hull:\n",
    "                p = point[0]\n",
    "                points.append(list(p))\n",
    "            #cv.drawContours(img, [hull], -1, (0, 255,0 ), 1)\n",
    "    vert = remove_unnecessary_vertexes(points, w ,h)\n",
    "    #print(vert)\n",
    "    return vert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестовая фигня (потом удалить) $\\downarrow$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_contour_amount = 0\n",
    "for i in np.arange(25, 40):\n",
    "#for i in np.arange(len(images_pth)):\n",
    "    img = cv.imread(images_pth[i])\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    img = cv.resize(img, (512, 112), fx=1, fy=1, interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "    #thresh = adaptive(img)\n",
    "    #thresh = global_thresh(img)\n",
    "    thresh = stof_blur(img)\n",
    "\n",
    "    conts, hier = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = sorted(conts, key=cv.contourArea, reverse=True)[:5]\n",
    "\n",
    "    points = []\n",
    "    for cont in cnts:\n",
    "        perimeter = cv.arcLength(cont, True)\n",
    "        approx = cv.approxPolyDP(cont, 0.02 * perimeter, True)\n",
    "        hull = cv.convexHull(approx, returnPoints=True)\n",
    "        if len(hull) in range(1, 11) and cv.contourArea(hull) / 512 / 112 > 0.3:\n",
    "            for point in hull:\n",
    "                p = point[0]\n",
    "                points.append(list(p))\n",
    "            cv.drawContours(img, [hull], -1, (0, 255,0 ), 2)\n",
    "    vert = remove_unnecessary_vertexes(points, w ,h)\n",
    "    if len(points) > 0: not_null_contour_amount+=1\n",
    "    print(f\"{i} {points} | {vert}\")\n",
    "    cv.imwrite(f'temp_crops/{i}.jpg', img)  \n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "print (not_null_contour_amount)\n",
    "draw('temp_crops/')\n",
    "removeFrom('temp_crops/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 3. Аффинные преобразования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_affine_transformations(img, vertexes):\n",
    "    \n",
    "    rows,cols,ch = img.shape\n",
    "    pts1 = np.float32([vertexes[0], vertexes[1], vertexes[2]])\n",
    "    pts2 = np.float32([[0, 0], [512, 0], [512, 112]])\n",
    "    M = cv.getAffineTransform(pts1,pts2)\n",
    "    dst = cv.warpAffine(img,M,(cols,rows))\n",
    "    #fig, (ax1, ax2) = plt.subplots(ncols=2)\n",
    "    #ax1.imshow(img)\n",
    "    #ax2.imshow(dst)\n",
    "\n",
    "    #for i in range(3):\n",
    "    #    f = pts1[i]\n",
    "    #    d = pts2[i]\n",
    "    #    ax1.scatter(f[0], f[1], color='red')\n",
    "    #    ax2.scatter(d[0], d[1], color='red')\n",
    "    #plt.show()\n",
    "    return dst\n",
    "\n",
    "\n",
    "#img = cv.imread('0a6aa844e3834971.jpg')\n",
    "#points = find_vertex(img)\n",
    "#img1 = make_affine_transformations(img, points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестовая фигня (потом удалить) $\\downarrow$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('fdc3e7b9662f7229.jpg')\n",
    "img = cv.resize(img, (512, 112), fx=1, fy=1, interpolation=cv.INTER_CUBIC)\n",
    "#assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "vertex = find_vertex(img)\n",
    "rows,cols,ch = img.shape\n",
    "pts1 = np.float32([vertex[0], vertex[1], vertex[2]])\n",
    "pts2 = np.float32([[0, 0], [512, 0], [512, 112]])\n",
    "\n",
    "\n",
    "M = cv.getAffineTransform(pts1,pts2)\n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2)\n",
    "ax1.imshow(img)\n",
    "ax2.imshow(dst)\n",
    "\n",
    "for i in range(3):\n",
    "    f = pts1[i]\n",
    "    d = pts2[i]\n",
    "    ax1.scatter(f[0], f[1], color='red')\n",
    "    ax2.scatter(d[0], d[1], color='red')\n",
    "    #ax3.scatter(d[0], d[1], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для деформации изображения\n",
    "\n",
    "def img_deformation(img):\n",
    "  # Шаг 1.\n",
    "  img1 = image_segmentation(img)\n",
    "  \n",
    "  # Шаг 2.\n",
    "  vertexes = find_vertex(img1)\n",
    "  \n",
    "  # Шаг 3.\n",
    "  img3 = make_affine_transformations(img1, vertexes)\n",
    "  return img3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('fdc3e7b9662f7229.jpg')\n",
    "img1 = image_segmentation(img)\n",
    "vertexes = find_vertex(img1)\n",
    "img3 = make_affine_transformations(img1, vertexes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация и проверка метрикой полученного результата"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализация по шаблону 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(DATASET_PATH, show_template=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализация по шаблону 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(DATASET_PATH, show_template=True, template = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрику будем вычислять по формуле:\n",
    "$$Accuracy = \\frac{\\text{Количество правильных попадании}}{\\text{Количество символов в номере}}.$$\n",
    "Если номера имеют разную размерность, то возвращаем ноль."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(correct, prediction):\n",
    "    correct_arr = list(correct)\n",
    "    prediction_arr = list(prediction)\n",
    "    if len(correct_arr) != len(prediction_arr): return 0.0\n",
    "    correct_liter = 0\n",
    "    for i in range(len(correct_arr)):\n",
    "        if correct_arr[i] == prediction_arr[i]:\n",
    "            correct_liter += 1\n",
    "    return correct_liter    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('modelPredict.csv')\n",
    "correct_df = pd.read_csv('correspondance.csv').sort_values(by = 'image_name')\n",
    "merged_df = pd.merge(correct_df, df, on = \"image_name\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_2 = []\n",
    "prediction_3 = []\n",
    "for i in range(len(merged_df)):\n",
    "    prediction_2.append(int(metric(merged_df[\"number\"][i], merged_df[\"prediction_region_length_2\"][i])))\n",
    "    prediction_3.append(int(metric(merged_df[\"number\"][i], merged_df[\"prediction_region_length_3\"][i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.insert(4, \"prediction2_correct_amount\", prediction_2, True)\n",
    "merged_df.insert(5, \"prediction2_correct_accuracy\", [value / 8.0 for value in prediction_2], True)\n",
    "merged_df.insert(6, \"prediction3_correct_amount\", prediction_3, True)\n",
    "merged_df.insert(7, \"prediction3_correct_accuracy\", [value / 9.0 for value in prediction_3], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Аварийная пилюля на случай если наделали лишних столбцов\n",
    "\n",
    "merged_df = merged_df.drop(\"prediction2_correct_amount\", axis=1)\n",
    "merged_df = merged_df.drop(\"prediction2_correct_accuracy\", axis=1)\n",
    "merged_df = merged_df.drop(\"prediction3_correct_amount\", axis=1)\n",
    "merged_df = merged_df.drop(\"prediction3_correct_accuracy\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Avg accuracy for 2: {np.average([value / 8.0 for value in prediction_2])}\")\n",
    "print(f\"Avg accuracy for 3: {np.average([value / 9.0 for value in prediction_3])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
